---
layout: post
title:      "An Introdution to Statistical Learning <br>"
date:       2019-02-25 02:14:42 +0000
permalink:  an_introdution_to_statistical_learning_br
---

## With Applications in R <br>
### by  Gareth James • Daniela Witten • Trevor Hastie Robert Tibshirani<br>

### Chapter 1 <br>
#### Introduction<br>

##### Why this book?  We are using Python and Learn.co has enough material to assure I have no social life for the time being<br>

Every time I have had the oppurtunity to talk to a data scientist that switched into the field from something other than statistics.  This book has popped up as a book I should work my way through.  Yesterday was the 4th time this month somebody mentioned the book, so I decided that I should just do it.  And the easiest way to force my way through is to document the journey.  <br>

#### Useful links and resources<br>
This book can be bought on amazon for about $70. And there are several  youtube video series that goes through the book.  The link I was refered to was `https://youtu.be/p9n2w236B48 ` .  However, I am sure others are just as useful.  2 of the people that told me to read the book referenced the Coursera course that uses this as the basis of the curriculmn but they may have since taken that course down since I cannot find it.  If you know where it is please reply in the comment section!  <br>

Data Sets: `http://www-bcf.usc.edu/~gareth/ISL/data.html`<br>
Free PDF of Book : `http://www-bcf.usc.edu/~gareth/ISL/ISLR%20First%20Printing.pdf`<br>
R Code : `http://www-bcf.usc.edu/~gareth/ISL/code.html`<br>
Lecture Slides and Video : `http://fs2.american.edu/alberto/www/analytics/ISLRLectures.html`<br>


#### Text Notes<br>
Chapter one just briefly covers what will be gone over throughout the rest of the book.  Basically, it is a dumbed down version of a book called Elements of Statistical Learning or ESL for short.  If you are brave enough, that book can be found here `https://web.stanford.edu/~hastie/Papers/ESLII.pdf`.
As of right now, I plan to read that book next.  But, there are so many texts that I need to get through over the next 7 months that I am being very optimistic in thinking that I will get to that any time soon. <br> 

Chapter one also goes briefly over the history of Statistical learning.  For instance; in the 19th century Legendre & Gauss published the **Method of Least Squares**.  Which is now known as linear regression. <br>

Around 1970 we are introduced to :<br>
**Linear Regression**- is used for predicting quantitative values using continuous target. The input variables have any measurement level.  And, the predicted values are teh mean of the target variable at the input variables given value. <br>

**Logistical Regression**- uses categorical variables as the target variable (meaning that the value is binary or ordinal).  And the predictions you come up with using a logistical regression finds the probability of the target variables specific target step given the inputs used.<br>

Around the 1980's: <br>
Computers started to become powerful enough to run multiple linear regression models that were previously impossible.  This is when things such as **Classification and Regression Trees** were created.  And, it has been a fast evolution into more advanced machine learning techniques ever since.<br>


We are also given a breakdown of the notations they will use throughout the book and an overview of the datasets.  <br>  

#### Until next time!

